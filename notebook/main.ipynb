{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jY7ggRLWJDV",
        "outputId": "271d52fd-060b-4c53-961c-afac2cd033c6"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    on_colab = True\n",
        "\n",
        "    !gdown --id 1plmOCxV7HpXxqzW9b76jqeS2F96d-gX0 -O depth.zip\n",
        "    !unzip depth.zip -d .\n",
        "\n",
        "    !gdown --id 1-ch7BgX9oDCbk3LXDkKYve5mwFOp4zlX -O images.zip\n",
        "    !unzip images.zip -d ./tmasks\n",
        "\n",
        "except ImportError:\n",
        "    on_colab = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQc1oLNoYAvL",
        "outputId": "8b96c118-33e4-48fc-9814-3a43ef023dd7"
      },
      "outputs": [],
      "source": [
        "if on_colab:\n",
        "    !git clone https://github.com/hamidrezafahimi/depth_pattern_analysis.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HNiG95UHSHC1"
      },
      "outputs": [],
      "source": [
        "on_colab = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DCUVVgq2hIz1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from torchvision import transforms\n",
        "\n",
        "if on_colab:\n",
        "    sys.path.append('/content/depth_pattern_analysis/train')\n",
        "    imgdir = '/content/depth'\n",
        "    patdir = '/content/tmasks'\n",
        "    chdir = '/content/checkpoints'\n",
        "    os.makedirs(\"/content/output\", exist_ok=True)  # Creates the folder if it doesn't exist\n",
        "    outputdir = \"/content/output/\"\n",
        "else:\n",
        "    sys.path.append('../train')\n",
        "    imgdir = '../data/depth'\n",
        "    patdir = '../data/tmasks'\n",
        "    chdir = '../data/checkpoints'\n",
        "    outputdir = \"../data/output/\"\n",
        "\n",
        "# Optionally, additional transforms (e.g., normalization) can be added\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "from temp1 import *\n",
        "# Create model and dataloader for training\n",
        "model, dataloader = create_model(imgdir, patdir, batch_size=4, transform=transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq4CmirRzNp4",
        "outputId": "7e11ff7f-2282-4bfc-ec87-d7f24fb68341"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_8796/3047454835.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model (update hyperparameters as needed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/media/hamid/Workspace/dpa-unet/train/temp1.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, epochs, lr, device, checkpoint_interval, checkpoint_dir)\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mth_pattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemplate_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth_pattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0mloss_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/yv8mt/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[1;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         )\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/yv8mt/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Train the model (update hyperparameters as needed)\n",
        "train_model(model, dataloader, epochs=20, lr=1e-4, device='cuda', checkpoint_interval=5, checkpoint_dir=chdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HSnmYx-JF7d",
        "outputId": "cbb51e9e-89a0-4ccf-a088-96b72f258f1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved masked image to ./output/masked_image.png\n",
            "Saved threshold pattern to ./output/threshold_pattern.png\n",
            "Saved template mask to ./output/template_mask.png\n"
          ]
        }
      ],
      "source": [
        "# Paths (update these with your own file paths)\n",
        "model_checkpoint = './checkpoints/checkpoint_epoch_20.pth'  # path to the trained model checkpoint\n",
        "input_image_file = './depth/00000001.jpg'         # a single depth image file\n",
        "template_mask_file = './tmasks/00000001.jpg'       # corresponding template mask file\n",
        "output_directory = './output'\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "evaluate_model(model_checkpoint, input_image_file, template_mask_file, output_directory, device=device)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
