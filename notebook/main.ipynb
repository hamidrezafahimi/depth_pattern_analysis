{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jY7ggRLWJDV",
        "outputId": "733cd96a-c725-4720-865b-680815c62b9b"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    on_colab = True\n",
        "\n",
        "    !gdown --id 1egJIl0p1rw3FAaeumFQ5ydYhZCKsrt67 -O patterns.zip\n",
        "    !unzip patterns.zip -d ./patterns\n",
        "\n",
        "    !gdown --id 1hYjHNM6333H8-53bF4jimIVRfhM8JxML -O images.zip\n",
        "    !unzip images.zip -d ./images\n",
        "\n",
        "except ImportError:\n",
        "    on_colab = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQc1oLNoYAvL",
        "outputId": "3284ff76-b680-453b-dd67-cd017224fdb3"
      },
      "outputs": [],
      "source": [
        "if on_colab:\n",
        "    !git clone https://github.com/hamidrezafahimi/depth_pattern_analysis.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "DCUVVgq2hIz1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "if on_colab:\n",
        "    sys.path.append('/content/depth_pattern_analysis/train')\n",
        "    imgdir = '/content/images'\n",
        "    patdir = '/content/patterns'\n",
        "    chdir = '/content/checkpoints'\n",
        "    os.makedirs(\"/content/output\", exist_ok=True)  # Creates the folder if it doesn't exist\n",
        "    outputdir = \"/content/output/\"\n",
        "else:\n",
        "    sys.path.append('../train')\n",
        "    imgdir = '../data/images'\n",
        "    patdir = '../data/patterns'\n",
        "    chdir = '../data/checkpoints'\n",
        "    outputdir = \"../data/output/\"\n",
        "\n",
        "from helper1 import *\n",
        "model, dataloader = create_model(img_directory=imgdir, pat_directory=patdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq4CmirRzNp4",
        "outputId": "0c4459bb-329e-481d-e605-5498905648a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Loss: 0.0320\n",
            "Epoch [2/20], Loss: 0.0211\n",
            "Epoch [3/20], Loss: 0.0169\n",
            "Epoch [4/20], Loss: 0.0149\n",
            "Epoch [5/20], Loss: 0.0147\n",
            "Checkpoint saved at ./checkpoints/checkpoint_epoch_5.pth\n",
            "Epoch [6/20], Loss: 0.0137\n",
            "Epoch [7/20], Loss: 0.0139\n",
            "Epoch [8/20], Loss: 0.0146\n",
            "Epoch [9/20], Loss: 0.0133\n",
            "Epoch [10/20], Loss: 0.0133\n",
            "Checkpoint saved at ./checkpoints/checkpoint_epoch_10.pth\n",
            "Epoch [11/20], Loss: 0.0131\n",
            "Epoch [12/20], Loss: 0.0131\n",
            "Epoch [13/20], Loss: 0.0126\n",
            "Epoch [14/20], Loss: 0.0130\n",
            "Epoch [15/20], Loss: 0.0130\n",
            "Checkpoint saved at ./checkpoints/checkpoint_epoch_15.pth\n",
            "Epoch [16/20], Loss: 0.0123\n",
            "Epoch [17/20], Loss: 0.0123\n",
            "Epoch [18/20], Loss: 0.0126\n",
            "Epoch [19/20], Loss: 0.0124\n",
            "Epoch [20/20], Loss: 0.0126\n",
            "Checkpoint saved at ./checkpoints/checkpoint_epoch_20.pth\n"
          ]
        }
      ],
      "source": [
        "train_model(model, dataloader, epochs=20, alpha=0.01, lr=1e-4, device='cuda', checkpoint_dir=chdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiDnEFu6zZad",
        "outputId": "6d8de3ff-aa5f-4c85-9b33-ce94655d4f22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved: x_input.jpg, p_pattern.jpg, m_predicted.jpg (random index 2)\n"
          ]
        }
      ],
      "source": [
        "# Inference on new data\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Set device (GPU if available, else CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load model\n",
        "e_model = EncoderDecoder(in_channels=2).to(device)  # Ensure model is moved to device\n",
        "\n",
        "checkpoint = torch.load(chdir + \"/checkpoint_epoch_20.pth\", map_location=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "e_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "\n",
        "# Set model to evaluation mode\n",
        "e_model.eval()\n",
        "\n",
        "# Run inference\n",
        "with torch.no_grad():\n",
        "    for x_test, p_test in dataloader:\n",
        "        x_test = x_test.cuda()\n",
        "        p_test = p_test.cuda()\n",
        "        m_pred = e_model(x_test, p_test)  # shape (B,1,H,W)\n",
        "\n",
        "        # Pick a random index from the batch\n",
        "        rand_idx = random.randint(0, x_test.shape[0] - 1)\n",
        "\n",
        "        # Extract the randomly chosen sample\n",
        "        x_sample = x_test[rand_idx].cpu().numpy().squeeze()\n",
        "        p_sample = p_test[rand_idx].cpu().numpy().squeeze()\n",
        "        m_sample = m_pred[rand_idx].cpu().numpy().squeeze()\n",
        "\n",
        "        # Convert arrays to grayscale images and save\n",
        "        Image.fromarray((x_sample * 255).astype(np.uint8)).save(outputdir + \"x_input.jpg\")\n",
        "        Image.fromarray((p_sample * 255).astype(np.uint8)).save(outputdir + \"p_pattern.jpg\")\n",
        "        Image.fromarray((m_sample * 255).astype(np.uint8)).save(outputdir + \"m_predicted.jpg\")\n",
        "\n",
        "        print(f\"Saved: x_input.jpg, p_pattern.jpg, m_predicted.jpg (random index {rand_idx})\")\n",
        "        break  # Save only one random sample, then exit loop"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
